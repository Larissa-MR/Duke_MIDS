{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Your Own Linear Regression Model by **Larissa due XY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exc. 1\n",
    "\n",
    "Define a new Class called MyLinearModel with methods for __init__, fit, predict, and an attribute for coefficients. For now, we don’t need any initialization arguments, just an __init__ function.\n",
    "\n",
    "As you get your code outline going, start by just having each method pass...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearModel:\n",
    "    ## define init method\n",
    "    def __init_(self):\n",
    "        pass\n",
    "    def fit(self):\n",
    "        pass\n",
    "        self.coefficient = ''\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exc. 2\n",
    "Now define your fit method. This is the method that should actually run your linear regression. In case you’ve forgotten your linear algebra, remember that for linear regressions, , a fact you can see explained in detail on page four here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MyLinearModel:\n",
    "    ## define init method\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.coef = None\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y \n",
    "        b = np.linalg.inv(self.X.transpose()@self.X)@(self.X.transpose()@self.Y)\n",
    "        self.coef = b\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exc.3\n",
    "As you write code, it is good to test your code as you work. With that in mind, let’s create some toy data. First, create a 100 x 2 matrix where each column is normally distributed. Then create a vector y that is a linear combination of those two columns plus a vector of normally distributed noise and a constant term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in our dataset is: 100\n"
     ]
    }
   ],
   "source": [
    "matrix = np.random.normal(size = (100, 2))\n",
    "assert matrix.shape == (100, 2)\n",
    "y = matrix[:,[0]] *3 + matrix[:,[1]] *8 + np.random.normal(size=(100,1)) + 10\n",
    "#y\n",
    "print(\"Total samples in our dataset is: {}\".format(y.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exc. 4\n",
    "Now test whether you fit method generates the correct coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3.56346246, 7.00305854]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fit = MyLinearModel()\n",
    "test_fit.fit(matrix, y)\n",
    "betas = test_fit.coef.T\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exc. 5\n",
    "Now let’s make the statisticians proud, and in addition to storing the coefficients, let’s store the standard errors for our estimated coefficients as another attribute. Recall that the simplest method of calculating the variance covariance matrix for  is using the formula , where  is the variance of the error terms of your regression. See page six here for a full derivation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exc. 6\n",
    "Now let’s also add an R-squared attribute to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exc. 7\n",
    "Now we’ll go ahead and cheat a little. Use statsmodels to fit your model with your toy data to ensure your standard errors and r-squared are correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exc. 8\n",
    "Now implement predict! Then test it against your original X data – do you get back something very close to your true y?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MyLinearModel:\n",
    "    ## define init method\n",
    "    def __init_(self):\n",
    "        pass\n",
    "    def fit(self):\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            self.params = self.params - (self.alpha/self.n_samples) * \\\n",
    "            self.X.T @ (self.X @ self.params - self.y)\n",
    "\n",
    "        self.intercept_ = self.params[0]\n",
    "        self.coef_ = self.params[1:]\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "      def predict( self, X ) :\n",
    "      \n",
    "        return X.dot( self.W ) + self.b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exc. 9\n",
    "Finally, create the option of fitting the model with or without a constant term. In other words, create an option so that, if the user passes a numpy array without a constant term, your code will add a vector of 1s before fitting the model. As in scikit-learn, make this an option you set during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b06e8dae6549768e568d0f3a66b6ab8b92ae2f538ca336b4fcd706f8ba3ac8d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python396jvsc74a57bd050292dbb1f747f7151d445135d392af3138fb3c65386d17d9510cb605222b10b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "50292dbb1f747f7151d445135d392af3138fb3c65386d17d9510cb605222b10b"
   }
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}